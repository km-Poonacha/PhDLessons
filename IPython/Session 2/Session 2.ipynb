{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 2\n",
    "\n",
    "JSON and API\n",
    "*authentication Oauth\n",
    "HTML and Webscraping\n",
    "Modules - requests,urllib2,oauth,beautifulsoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "An application programming interface is a set of functions that you call to get access to some service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Urllib module\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit about OAuth\n",
    "Finding the consumer key and secrets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requests module\n",
    "\n",
    "Web client development with requests is easier \n",
    "pip install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "url = 'http://hec.fr'\n",
    "resp = requests.get(url)\n",
    "resp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crawl and scrape\n",
    "\n",
    "Sometimes, you may want a little bit of information - a movie rating, stock price, or product availability - but the information is available only in HTML pages, surrounded by ads and extraneous content.\n",
    "\n",
    "To do this we build an automated web fetcher called a crawler or spider. After teh HTML contents have been retrived from the remote web servers, a scraper parses it to find the needle in the haystack.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapy Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BeautifulSoup Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the document is converted to Unicode, and HTML entities are converted to Unicode characters:\n",
    "Beautiful Soup then parses the document using the best available parser. It will use an HTML parser unless you specifically tell it to use an XML parser. WHat is parsing ?\n",
    "\n",
    "Beautiful Soup transforms a complex HTML document into a complex tree of Python objects. But youâ€™ll only ever have to deal with about four kinds of objects: Tag, NavigableString, BeautifulSoup, and Comment.\n",
    "\n",
    "A Tag object corresponds to an XML or HTML tag in the original document:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
